# Text Representation Models

## Learning Outcomes

* Traditional Text Representation Models
* Hands-on examples of Text Representation Models \(Statistical\)
* Word Embedding Models with hands-on examples 

## Learning Resources

<iframe width="560" height="315" src="https://www.youtube.com/embed/q0sdzofQ9cw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

* Links to the notebooks for hands-on practice: 
  * [Text Representation Statistical Models](https://github.com/dphi-official/nlp_essentials/blob/master/notebooks/02_Text_Representation_Statistical_Models.ipynb)
  * [Text Representation Embedding Models](https://github.com/dphi-official/nlp_essentials/blob/master/notebooks/03_Text_Representation_Embedding_Models.ipynb)

## Additional Resources

We recommend you to go through the following article that gives a comprehensive overview about Text Representation for NLP:

* [Introduction to Text Representation - Part 1](https://towardsdatascience.com/introduction-to-text-representations-for-language-processing-part-1-dc6e8068b8a4)
* [Introduction to Text Representation - Part 2](https://towardsdatascience.com/introduction-to-text-representations-for-language-processing-part-2-54fe6907868)